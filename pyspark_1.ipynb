{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveen-S6/Python_practice/blob/main/pyspark_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7dAYlH5N6Kv"
      },
      "source": [
        "## üßëüèº‚Äçüîß PySpark Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b17JV3v1MtR1"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install -q delta-spark==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hGjXgPKBNmHT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IiCzLVOnWhVN"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from delta.tables import DeltaTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yRvxGXD_Nqdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "31917a8e-081e-47d5-c5ff-c98b98912d22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7d3f5281fd70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://33658ff2cf18:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Airbnb_Cleanup</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"Airbnb_Cleanup\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ade373b5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KIHeYDRKbcsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6b6e2c-edd9-4613-eaff-6116ce5a46a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Generated 600 Airbnb listings at /content/listings.json\n",
            "{\"id\": 101, \"name\": \"Spacious Condo in Bangalore\", \"amenities\": [\"Balcony\", \"TV\", \"Gym\", \"Hot tub\", \"Pool\", \"Garden\", \"Parking\", \"Washer\"], \"has_parking\": true, \"is_superhost\": \"Yes\"}\n",
            "{\"id\": 102, \"name\": \"Luxury Villa in Mumbai\", \"amenities\": [\"Essentials\", \"Mountain view\", \"Fireplace\", \"Dryer\", \"Parking\", \"Gym\"], \"has_parking\": \"Yes\", \"is_superhost\": \"Yes\"}\n",
            "{\"id\": 103, \"name\": \"Cozy Loft in Chennai\", \"amenities\": [\"Pool\", \"Hot tub\", \"Breakfast\", \"Heating\", \"Dryer\", \"Balcony\"], \"has_parking\": \"FALSE\", \"is_superhost\": \"FALSE\"}\n",
            "{\"id\": 104, \"name\": \"Cozy Bungalow in Mumbai\", \"amenities\": [\"Breakfast\", \"TV\", \"Washer\"], \"has_parking\": false, \"is_superhost\": \"Yes\"}\n",
            "{\"id\": 105, \"name\": \"Budget Villa in Hyderabad\", \"amenities\": [\"Parking\", \"Breakfast\", \"Mountain view\", \"Workspace\", \"Washer\", \"Heating\"], \"has_parking\": true, \"is_superhost\": \"true\"}\n"
          ]
        }
      ],
      "source": [
        "# üßÆ Generate large Airbnb listings.json dataset (500+ records)\n",
        "import json, random\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "num_records = 600  # you can adjust to 500, 1000, etc.\n",
        "\n",
        "amenities_pool = [\n",
        "    \"Wifi\", \"Kitchen\", \"Washer\", \"Dryer\", \"TV\", \"Essentials\", \"Air conditioning\",\n",
        "    \"Heating\", \"Pool\", \"Hot tub\", \"Balcony\", \"Garden\", \"Parking\", \"Fireplace\",\n",
        "    \"Sea view\", \"Mountain view\", \"Pet friendly\", \"Gym\", \"Breakfast\", \"Workspace\"\n",
        "]\n",
        "\n",
        "property_types = [\n",
        "    \"Studio Apartment\", \"Private Room\", \"Entire Home\", \"Cottage\", \"Villa\",\n",
        "    \"Cabin\", \"Loft\", \"Guest Suite\", \"Bungalow\", \"Condo\"\n",
        "]\n",
        "\n",
        "cities = [\"Mumbai\", \"Bangalore\", \"Hyderabad\", \"Chennai\", \"Pune\", \"Delhi\", \"Goa\"]\n",
        "\n",
        "boolean_variants = [True, False, \"true\", \"false\", \"Yes\", \"No\", \"yes\", \"no\", \"TRUE\", \"FALSE\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Data generation logic\n",
        "# -----------------------------\n",
        "data = []\n",
        "\n",
        "for i in range(1, num_records + 1):\n",
        "    record = {\n",
        "        \"id\": 100 + i,\n",
        "        \"name\": f\"{random.choice(['Cozy', 'Modern', 'Luxury', 'Spacious', 'Budget'])} \"\n",
        "                f\"{random.choice(property_types)} in {random.choice(cities)}\",\n",
        "        \"amenities\": random.sample(amenities_pool, random.randint(3, 8)),\n",
        "        \"has_parking\": random.choice(boolean_variants),\n",
        "        \"is_superhost\": random.choice(boolean_variants)\n",
        "    }\n",
        "    data.append(record)\n",
        "\n",
        "# -----------------------------\n",
        "# Write to JSON file (line-delimited)\n",
        "# -----------------------------\n",
        "file_path = \"/content/listings.json\"\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    for row in data:\n",
        "        json.dump(row, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Generated {len(data)} Airbnb listings at {file_path}\")\n",
        "\n",
        "# Quick sanity check\n",
        "!head -n 5 /content/listings.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6W0vNsRX4Ch"
      },
      "source": [
        "\n",
        "# ‚ùì Scenario Question: Airbnb ‚Äî Clean Listing Amenities (PySpark) [Easy]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCQ8sDM6cF2d"
      },
      "source": [
        "---\n",
        "\n",
        "## üóÇÔ∏è Scenario\n",
        "\n",
        "You are working with raw Airbnb listing data ingested from multiple sources.  \n",
        "Each listing contains details about the property and a nested list of amenities.  \n",
        "The goal is to clean and normalize this data for easier analysis downstream.\n",
        "\n",
        "The data is available as a JSON file (`listings.json`) in the **Bronze layer**, which now needs to be processed into a structured **Silver table**.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Task\n",
        "\n",
        "Perform the following transformations:\n",
        "\n",
        "1. **Read** the input data from `listings.json` using Spark.  \n",
        "2. **Explode** the `amenities` array so that each row contains a single amenity.  \n",
        "3. **Normalize** boolean-like columns (e.g., `\"true\"`, `\"false\"`, `\"yes\"`, `\"no\"`) to proper `true`/`false` Spark booleans.  \n",
        "4. **Rename** or select only the relevant columns for downstream use.  \n",
        "5. **Write** the cleaned result as a **Delta table**\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Assumptions\n",
        "\n",
        "- Input file `listings.json` is already available in the `/content/` directory.  \n",
        "- The `amenities` field may contain an array or a string representation of an array.  \n",
        "- Boolean columns may contain a mix of lowercase/uppercase strings or actual booleans.  \n",
        "- Only essential columns (`id`, `name`, `amenity`, and boolean columns) are required in the output.  \n",
        "- If a column is missing or malformed, handle it gracefully (e.g., cast to null).\n",
        "\n",
        "---\n",
        "\n",
        "## üì¶ Deliverables\n",
        "\n",
        "- **Output Location:** `/content/silver/listing_amenities`  \n",
        "\n",
        "| **Output Format** | Delta |\n",
        "\n",
        "| **Expected Columns** | `id`, `name`, `amenity`, `has_parking`, `is_superhost` |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Notes\n",
        "\n",
        "- Use `pyspark.sql.functions.explode()` to expand the amenities array.  \n",
        "- Use `F.col().cast(\"boolean\")` or `F.when()` for type normalization.  \n",
        "- Maintain clear naming consistency in column aliases.  \n",
        "- After writing, the Delta table should be queryable from the `spark.read.format(\"delta\")` API.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSTZBIoGcjOM"
      },
      "source": [
        "## üõ¢Ô∏èInput data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UduvjFkYN09B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3191e7-05db-4163-feba-50a61ec46e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------+-----------+---+------------+---------------------------+\n",
            "|amenities                                                      |has_parking|id |is_superhost|name                       |\n",
            "+---------------------------------------------------------------+-----------+---+------------+---------------------------+\n",
            "|[Balcony, TV, Gym, Hot tub, Pool, Garden, Parking, Washer]     |true       |101|Yes         |Spacious Condo in Bangalore|\n",
            "|[Essentials, Mountain view, Fireplace, Dryer, Parking, Gym]    |Yes        |102|Yes         |Luxury Villa in Mumbai     |\n",
            "|[Pool, Hot tub, Breakfast, Heating, Dryer, Balcony]            |FALSE      |103|FALSE       |Cozy Loft in Chennai       |\n",
            "|[Breakfast, TV, Washer]                                        |false      |104|Yes         |Cozy Bungalow in Mumbai    |\n",
            "|[Parking, Breakfast, Mountain view, Workspace, Washer, Heating]|true       |105|true        |Budget Villa in Hyderabad  |\n",
            "+---------------------------------------------------------------+-----------+---+------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# üßÆ Load and preview the sample dataset\n",
        "df = spark.read.json(\"/content/listings.json\")\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBDbcY2enlu"
      },
      "source": [
        "# üìù Your Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b5nNsMI_eiYy"
      },
      "outputs": [],
      "source": [
        "# ‚úçÔ∏è Your Solution Here\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Steps:\n",
        "# 1. Read the JSON file\n",
        "# 2. Explode the amenities\n",
        "# 3. Normalize boolean-like fields and retrun the dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cuYtHdS8htLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wQjta8aIevl6"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------\n",
        "# üß† Spark Practice Challenge #1 ‚Äî Airbnb Listing Cleanup\n",
        "# -------------------------------------------------------\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# 1Ô∏è‚É£ Read the raw JSON file\n",
        "df = spark.read.json(\"/content/listings.json\")\n",
        "\n",
        "# 2Ô∏è‚É£ Explode the amenities array\n",
        "df_exploded = df.withColumn(\"amenity\", F.explode(\"amenities\"))\n",
        "\n",
        "# 3Ô∏è‚É£ Normalize boolean-like fields\n",
        "# Define a helper function to convert messy boolean formats to true/false\n",
        "def normalize_boolean(col):\n",
        "    return (\n",
        "        F.when(F.lower(F.col(col)).isin(\"true\", \"yes\", \"y\", \"1\"), True)\n",
        "         .when(F.lower(F.col(col)).isin(\"false\", \"no\", \"n\", \"0\"), False)\n",
        "         .otherwise(F.col(col).cast(\"boolean\"))\n",
        "    )\n",
        "\n",
        "df_cleaned = (\n",
        "    df_exploded\n",
        "    .withColumn(\"has_parking\", normalize_boolean(\"has_parking\"))\n",
        "    .withColumn(\"is_superhost\", normalize_boolean(\"is_superhost\"))\n",
        ")\n",
        "\n",
        "# 4Ô∏è‚É£ Select required columns\n",
        "df_final = df_cleaned.select(\"id\", \"name\", \"amenity\", \"has_parking\", \"is_superhost\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sDVSRC3Lg5pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a44f1ac-aebb-4f18-cfda-4f593c6a253b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+-------+-----------+------------+\n",
            "| id|                name|amenity|has_parking|is_superhost|\n",
            "+---+--------------------+-------+-----------+------------+\n",
            "|101|Spacious Condo in...|Balcony|       true|        true|\n",
            "|101|Spacious Condo in...|     TV|       true|        true|\n",
            "|101|Spacious Condo in...|    Gym|       true|        true|\n",
            "|101|Spacious Condo in...|Hot tub|       true|        true|\n",
            "|101|Spacious Condo in...|   Pool|       true|        true|\n",
            "+---+--------------------+-------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_final.show(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "p6W0vNsRX4Ch",
        "ijBDbcY2enlu"
      ],
      "authorship_tag": "ABX9TyMam4C/mUCZEaa7uX585b4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}